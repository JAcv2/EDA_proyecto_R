---
title: "EDA Proyecto DataViz"
author: "Edward Morales - Julian Acevedo"
date: "2023-11-10"
output:   
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
    theme: "readable" #cosmo - journal
---
```{r setup}
knitr::opts_chunk$set(warning = FALSE)
```

# EDA proyecto

# Descripción de datos

El siguiente set de datos pertenece a una serie de interacciones registradas en un centro de llamadas por día a lo largo del tiempo. Los datos están registrados por fecha identificando si es un día feriado o no y la cantidad de llamadas registrada por día.

Descripción de columnas:
- Fecha: fecha de los registros.
- StateHoliday: indicador de días feriados.
- Real Calls: número de llamadas registrado en el día.


## Carga y visualización de datos

```{r}
library(readr)
df_proyect <- read_delim("C:/Users/Edward Morales/Documents/ts_dash.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE)
df_proyect$FECHA <- as.Date(df_proyect$FECHA, format = "%d/%m/%Y")

knitr::kable(head(df_proyect, 10))
```

En la tabla se pueden visualizar la carga de los datos y los primeros 10 registros.

## Descripción de los datos

```{r}
summary(df_proyect)
```

La descripción de los datos muestra que el dataset cuenta con 1367 registros, la variable objetivo 'REAL CALLS' tiene una media de 2215.41.

## Información de los datos

```{r}
str(df_proyect)
```
En la información de los datos descubrimos el tipo de dato date en la columna 'FECHA' y tipo num para las columnas 'StateHoliday' y 'REAL CALLS', en todos sin datos null.


## verificar datos unicos

```{r}
nunique <- sapply(df_proyect, function(x) length(unique(x)))
nunique
```
Al verificar datos únicos encontramos que la columna 'FECHA' tiene 1367 datos únicos por lo tanto no tiene ningún datos repetido, la columna 'StateHoliday' tiene 3 datos únicos y suele ser el identificador del día feriado y la columna 'REALL CALLS' presenta 1039 datos únicos esto quiere decir que se tienen  328 registros donde se repite la cantidad de llamadas reales.


## Visualizacion de los datos

```{r}
library(ggplot2)

ggplot(df_proyect, aes(x = FECHA, y = `REAL CALLS`)) +
  geom_line() + 
  labs(title = 'Serie Temporal de Real Calls', 
       x = 'Fecha', 
       y = 'Número de Llamadas') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 50, vjust = 1, hjust = 1))
```
En este grafico se logra identificar que la serie presenta una tendencia positiva.


## Histograma

```{r}
library(ggplot2)
bins_sturges <- 1 + log2(length(df_proyect$`REAL CALLS`))
ggplot(df_proyect, aes(x = `REAL CALLS`)) +
    geom_histogram(aes(y = ..density..), bins_sturges=bins_sturges, colour = "black", fill = "white") +
    geom_density(alpha = .2, fill = "#FF6666") +
    labs(title = 'Histograma de REAL CALLS', x = 'REAL CALLS', y = 'Frecuencia')

```
Graficando el histograma se puede identificar que los datos presentan una concentración de datos principalmente a la izquierda de la distribución.


## Boxplot

```{r}
library(ggplot2)
ggplot(df_proyect, aes(y = `REAL CALLS`)) +
  geom_boxplot() +
  labs(title = 'Boxplot de REAL CALLS', x = 'REAL CALLS', y = '') +
  theme_minimal()
```

Graficando el boxplot se puede identificar que los datos presentan una concentración de datos principalmente a la izquierda de la distribución.

## Graficas de datos por año, mes y dia

```{r}
dff <- df_proyect
dff$AÑO <- format(dff$FECHA, "%Y")
dff$MES <- format(dff$FECHA, "%B")
dff$DiaSemana <- format(dff$FECHA, "%A")
head(dff)
```
Para graficar el comportamiento de los datos por año, mes y día es necesario crear las columnas 'AÑO', 'MES' y 'DiaSemana' con el objetivo de simplificar los filtros por cada una de las agrupaciones.

```{r}
library(ggplot2)
ggplot(dff, aes(x = as.factor(AÑO), y = `REAL CALLS`)) +
  geom_boxplot() +
  labs(title = 'Boxplot llamadas por Año', x = 'Año', y = 'Valor') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 00, hjust = 1))  # Rota las etiquetas del eje X
```

En la gráfica por año se observa que a la la medica que aumentan los años la cantidad de llamadas aumenta, lo cual explica gráficamente el comportamiento con tendencia positiva. 

```{r}
library(ggplot2)
dff$MES <- factor(dff$MES, levels = c("enero", "febrero", "marzo", "abril", "mayo", "junio", "julio", "agosto", "septiembre", "octubre", "noviembre", "diciembre"))
# Crear el boxplot
ggplot(dff, aes(x = MES, y = `REAL CALLS`)) +
  geom_boxplot() +
  labs(title = 'Boxplot llamadas por Mes', x = 'Mes', y = 'Valor') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rota las etiquetas del eje X

```
En la gráfica por meses de identifica una gran variabilidad en los datos a lo largo de cada uno de los meses. Meses como diciembre 'Didiciembre' que presentan una menor variabilidad que otros.

```{r}
library(ggplot2)
library(forcats)

# Ordenar los días de la semana
dff$DiaSemana <- factor(dff$DiaSemana, levels = c("lunes", "martes", "miércoles", "jueves", "viernes", "sábado", "domingo"))

# Crear el boxplot
ggplot(dff, aes(x = DiaSemana, y = `REAL CALLS`)) +
  geom_boxplot() +
  labs(title = 'Boxplot llamadas por Día de la Semana', x = 'Día', y = 'Valor') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rota las etiquetas del eje X

```

En los gráficos anteriores podemos identificar que la serie de tiempo de llamadas ha tenido una tendencia positiva a los largo del tiempo, adicional a esto se identifica visualmente una estacionalidad en el comportamiento de las llamadas a lo largo de los meses y mucho más pronunciada cuando lo vemos por día, se entiende que los lunes es cuando mayor cantidad de llamadas ingresa y va descendiendo hasta el día viernes, los sábados y domingos se tienen registros muy bajos de llamadas.


## Datos faltantes

```{r}
library(mice)
md.pattern(df_proyect, plot = TRUE, rotate.names = TRUE)
```


```{r}
sum(is.na(df_proyect$`REAL CALLS`))
```

El set de datos no tiene datos faltantes. Por lo tanto, no es necesario realizar análisis de datos faltantes.

# 2. Prueba Dickey-Fuller


```{r}
sum(df_proyect$`REAL CALLS`)
```
```{r}
head(df_proyect$`REAL CALLS`)
```
```{r}
tail(df_proyect$`REAL CALLS`)
```

```{r}
library(tseries)

# Realizar la prueba de Dickey-Fuller aumentada
dickey_fuller_result <- adf.test(df_proyect$`REAL CALLS`, k = 90)

# Extracción de los resultados
test_stat <- dickey_fuller_result$statistic
p_value <- dickey_fuller_result$p.value
alpha <- 0.05

cat("Hipótesis:\n")
cat("H0: Serie no estacionaria\n")
cat("H1: Serie estacionaria\n")
cat(sprintf("Estadístico de prueba: %.4f\n", test_stat))
cat(sprintf("p-value: %.4f\n", p_value))
cat(sprintf("Alpha: %f\n", alpha))
if (p_value > alpha) {
  cat("No se rechaza H0, por lo tanto la serie no es estacionaria.\n")
} else {
  cat("Se rechaza H0, por lo tanto la serie es estacionaria.\n")
}

```

# 3. Descomposición

```{r}
#ts_TGLS_2 <- ts(df_TGLS$Close, frequency=365, start=c(2012, 5))
ts_proyect <- ts(df_proyect$`REAL CALLS`,frequency=90)
library(TSstudio)
ts_decompose(ts_proyect)
```


Del gráfico de descomposición podemos concluir lo siguiente:

- Observado: muestra el comportamiento original de la serie.
- Tendencia: muestra la tendencia positiva que presenta la serie a lo largo del tiempo.
- Estacionalidad: muestra los patrones que se repiten en la serie, en este caso el patrón semanal es notorio.
- Residuos: muestran los errores del modelo y en este caso aparentan ser aleatorios y pequeños.


# 4. Transformacion de serie no estacionaria a estacionaria

```{r}
library(forecast)
library(ggplot2)

# Definir una función para crear un gráfico de diferenciación y ACF
plot_diff_acf <- function(data, lag.max, diff.order = 0, title.prefix = "") {
  # Aplicar diferenciación
  data.diff <- diff(data, differences = diff.order)
  
  # Crear gráfico de la serie de tiempo diferenciada
  plot.ts(data.diff, main = paste(title.prefix, "Order Differencing"), ylab = "Value")
  
  # Crear gráfico ACF
  Acf(data.diff, lag.max = lag.max, main = paste(title.prefix, "Order Differencing ACF"))
}

plot.ts(df_proyect$`REAL CALLS`, main = "Original Series", ylab = "Value")
Acf(df_proyect$`REAL CALLS`, lag.max = 90, main = "Real Calls")

for (i in 1:2) {
  plot_diff_acf(df_proyect$`REAL CALLS`, lag.max = 90, diff.order = i, title.prefix = paste(i, "nd"))
}

```

## Primera diferenciación

```{r}
library(tseries)

# Realizar la diferencia de la serie y eliminar valores NA
df_proyect_diff <- na.omit(diff(df_proyect$`REAL CALLS`, differences = 1))

# Realizar la prueba de Dickey-Fuller aumentada en la serie diferenciada
dickey_fuller_result <- adf.test(df_proyect_diff)

# Extracción de los resultados
test_stat <- dickey_fuller_result$statistic
p_value <- dickey_fuller_result$p.value
alpha <- 0.05

cat("Hipotesis:\n")
cat("H0: Serie no estacionaria\n")
cat("H1: Serie estacionaria\n")
cat(sprintf("Estadistico de prueba: %.4f\n", test_stat))
cat(sprintf("p-value: %.4f\n", p_value))
cat(sprintf("Alpha: %f\n", alpha))
if (p_value > alpha) {
  cat("No se rechaza H0, por lo tanto la serie no es estacionaria.\n")
} else {
  cat("Se rechaza H0, por lo tanto la serie es estacionaria.\n")
}

```

Realizando le primera diferenciacion y aplicando nuevamente el test de dicky-fuller concluimos que la serie se puede transformar de no estacionaria a estacionaria aplicando diferenciacion.

# Cambios Edward

```{r}
library(forecast)
library(ggplot2)

plot_diff_acf_pacf <- function(data, lag.max, diff.order = 0, title.prefix = "") {
  # Aplicar diferenciación
  data.diff <- diff(data, differences = diff.order)
  
  # Crear gráfico de la serie de tiempo diferenciada
  plot.ts(data.diff, main = paste(title.prefix, "Order Differencing"), ylab = "Value")
  
  # Crear gráfico ACF
  Acf(data.diff, lag.max = lag.max, main = paste(title.prefix, "Order Differencing ACF"))
  
  # Resaltar lags múltiplos de 7 en ACF
  abline(v = seq(7, lag.max, by = 7), col = "red", lty = 2)
  
  # Crear gráfico PACF
  Pacf(data.diff, lag.max = lag.max, main = paste(title.prefix, "Order Differencing PACF"))
  
  # Resaltar lags múltiplos de 7 en PACF
  abline(v = seq(7, lag.max, by = 7), col = "blue", lty = 2)
}

# Llamar a la función con los datos reales y la diferenciación de primer orden
plot_diff_acf_pacf(df_proyect$`REAL CALLS`, lag.max = 90, diff.order = 1, title.prefix = "1st")

```

La gráfica de la Función de Autocorrelación (ACF) para la primera diferenciación de una serie temporal muestra picos significativos en lags que son múltiplos de 7, lo que indica una estacionalidad semanal en los datos. Estos picos cruzan las bandas de significancia estadística, lo que sugiere que las correlaciones no son aleatorias sino que reflejan una verdadera relación estacional. No hay evidencia de correlaciones negativas significativas. La disminución gradual de la autocorrelación con lags más largos es típica después de la diferenciación. Esto sugiere que un modelo SARIMA podría ser adecuado para capturar la estacionalidad observada.


La gráfica de la Función de Autocorrelación Parcial (PACF) tras una primera diferenciación no muestra patrones de autocorrelación significativos en la mayoría de los lags, lo que sugiere que las correlaciones autoregresivas en los datos son limitadas. El único pico significativo en el primer lag podría indicar una posible relación autoregresiva de orden uno. La ausencia de picos significativos en los lags múltiplos de siete sugiere que la estacionalidad semanal no es evidente en la serie diferenciada. Esto podría indicar que una diferenciación adicional o un modelo ARIMA con un término autoregresivo simple podría ser adecuado para modelar estos datos.

```{r}
library(tseries)


# Asumiendo que 'df_proyect$`REAL CALLS`' es tu serie temporal
# Primero diferenciamos la serie
diff_series <- diff(diff(df_proyect$`REAL CALLS`, differences = 1),7)

# Ahora aplicamos la prueba de Dickey-Fuller Aumentada a la serie diferenciada
result <- adf.test(diff_series, alternative = "stationary")

# Imprimir los resultados de la prueba
print(result)

```
La salida del test de Dickey-Fuller muestra que el valor del estadístico de prueba es -19.277 y el valor-p es 0.01, menor que el umbral común de 0.05, lo cual nos permite rechazar la hipótesis nula de que la serie tiene una raíz unitaria (es decir, es no estacionaria) en favor de la hipótesis alternativa de que la serie es estacionaria. Esto indica que, después de diferenciar la serie temporal una vez, se ha alcanzado la estacionariedad.


# Modelo predictivo ARIMA
EN el EDA se utilizo s=7 ya que semanalmete estamos viendo los cambios, pero para esta parte no se utiliza ya que estamos viendo como ARIMA tiene un buen rendimento

```{r}
library(forecast)

df_proyect_AR <- arima(df_proyect$`REAL CALLS`, order = c(1, 1, 0))
summary(robusta_md)
```
El resumen del modelo ARIMA(1,1,0) muestra que el coeficiente para el término autoregresivo es pequeño y negativo (-0.0408), con un error estándar de 0.0270, lo que puede indicar una influencia leve pero probablemente significativa del valor previo en la predicción del valor actual. La varianza del error del modelo (sigma^2) es bastante grande, lo que sugiere que puede haber una buena cantidad de variabilidad no explicada en los datos. El AIC alto sugiere que el modelo podría mejorarse, posiblemente con términos adicionales o mediante la incorporación de la estacionalidad. Las medidas de error del conjunto de entrenamiento indican que el modelo tiene cierta precisión, pero sería prudente comparar con otros modelos y validarlos con un conjunto de datos de prueba. La autocorrelación residual (ACF1) cercana a cero sugiere que no hay autocorrelación significativa en los residuos.

```{r}
checkresiduals(robusta_md)
```
El resultado del test de Ljung-Box aplicado a los residuos del modelo ARIMA(1,1,0) indica un valor Q* muy alto (1788.2) con 9 grados de libertad y un valor p extremadamente bajo (menor que 2.2e-16). Esto sugiere que hay una autocorrelación significativa en los residuos a varios lags, lo cual implica que el modelo no está capturando toda la estructura de dependencia en los datos. En términos de modelado de series temporales, esto podría significar que el modelo actual es insuficiente y que podrían ser necesarios términos adicionales o un modelo diferente para explicar mejor la dinámica temporal de la serie.

# Modelo predictivo SARIMA

Un aves entedido estto agregamos la frecuensia = 7


```{r}
# Datos en formato de fecha y ordenados
calls_ts <- ts(df_proyect$`REAL CALLS`)

train_set <- head(calls_ts, -28)

test_set <- tail(calls_ts, 28)
```


```{r}
train_set7 <- diff(train_set, 7)

ts_plot(train_set7,
        title = "Real CALL - First Seasonal Difference",
        Ytitle = "Real CALL (Difference)",
        Xtitle = "Year")


```

Se logro eliminar la tendencia de la serie, pero sigue manteniedn la variación por ende la serie aún no es estable. Por lo tanto,tomamos la primera diferencia de la serie:


```{r}
train_set71 <- diff(diff(train_set7, 1))

ts_plot(train_set71,
        title = "Real CALL -  First Seasonal and Non-Seasonal Differencing",
        Ytitle = "Real CALL (Difference)",
        Xtitle = "Year")
```

Apesar de tomar la diferenciación de primer orden, junto con la diferenciación estacional de primer orden, la serie no se estabilizó en torno a la línea del eje x cero.

```{r}
par(mfrow=c(1,2))
acf(train_set71, lag.max = 60)
pacf(train_set71, lag.max = 60)
```
# Auto-ARIMA


```{r}
train_set <- ts(train_set, frequency = 7)
fit <- auto.arima(train_set, seasonal = TRUE)
fit

```
El modelo mejoro en comparación al anterior teniendo el anterior un AIC de (24071.5). Ademas el componente autoregresivo de primer orden (ar1) es positivo y significativo, lo que sugiere un fuerte efecto persistente de un periodo a otro. Los coeficientes de media móvil (ma1 y ma2) sugieren ajustes en la predicción basados en los errores de los dos periodos anteriores. Los términos estacionales de media móvil (sma1 y sma2) también son significativos, lo que indica patrones estacionales importantes en los datos. La varianza del error del modelo (sigma^2) y el logaritmo de verosimilitud indican el ajuste del modelo, y los valores de AIC y BIC relativamente bajos sugieren un buen equilibrio entre ajuste y complejidad del modelo.

```{r}
# Datos en formato de fecha y ordenados
calls_ts <- ts(df_proyect$`REAL CALLS`, frequency = 7)


train_set <- head(calls_ts, -28)

test_set <- tail(calls_ts, 28)

```

```{r}
# Pronosticar las siguientes 28 observaciones
forecast <- forecast(fit, h = 28)


```
```{r}
accuracy(forecast, test_set)
```
Los resultados muestran métricas de error para un conjunto de entrenamiento y un conjunto de prueba de un modelo de pronóstico. Las métricas indican un mejor rendimiento en el conjunto de entrenamiento que en el de prueba, como se ve en el menor RMSE y MAE. El valor positivo de ME (Error Medio) sugiere una subestimación sistemática en el conjunto de entrenamiento y una sobreestimación en el conjunto de prueba. La precisión del pronóstico para el conjunto de prueba, indicada por Theil's U, es relativamente baja, lo que sugiere que hay margen de mejora en el modelo. La significancia del ACF1 cercana a cero indica que no hay autocorrelación en los residuos, lo cual es positivo.

```{r}
test_forecast(calls_ts,
              forecast.obj = forecast,
              test = test_set)
```




```{r}
final_md <- arima(calls_ts, order = c(1,0,2), 
                  seasonal = list(order = c(0,1,2)))
```

```{r}
checkresiduals(final_md)

```

La salida del test de Ljung-Box para los residuos de un modelo SARIMA(1,0,2)(0,1,2)[7] muestra un estadístico Q* de 16.216 con 9 grados de libertad y un valor-p de 0.06251. Dado que el valor-p está justo por encima del umbral común de 0.05, no podemos rechazar la hipótesis nula de independencia en los residuos a un nivel de confianza del 95%. Esto sugiere que no hay evidencia suficiente de autocorrelaciones significativas en los residuos del modelo y que el modelo está capturando adecuadamente la estructura de autocorrelación de la serie temporal. Sin embargo, al estar tan cerca del límite, sería prudente revisar este resultado con diferentes números de lags y también comparar con otros modelos para confirmar la robustez del modelo actual.

```{r}
reall <- forecast(final_md, h = 28)


plot_forecast(reall,
              title = "Reall Call - Forecast",
              Ytitle = "Call",
              Xtitle = "Year")
```


```{r}
test_forecast(calls_ts,
              forecast.obj = forecast,
              test = test_set)
```



Manual

```{r}
best_ARIMA <- function(ts_in, p_n, d_n, q_n) {
  best_aic <- Inf
  best_order <- NULL
  best_seasonal_order <- NULL
  fit <- NULL
  
  for(p in 0:p_n) {
    for(d in 0:d_n) {
      for(q in 0:q_n) {
        for(P in 0:p_n) {
          for(D in 0:d_n) {
            for(Q in 0:q_n) {
              tryCatch({
                fit <- arima(ts_in, 
                             order = c(p, d, q), 
                             seasonal = list(order = c(P, D, Q), period = 7),
                             method = "CSS-ML")
                tmp_aic <- AIC(fit)
                if (tmp_aic < best_aic) {
                  best_aic <- tmp_aic
                  best_order <- c(p, d, q)
                  best_seasonal_order <- c(P, D, Q)
                }
              }, error = function(e){})
            }
          }
        }
      }
    }
  }
  
  return(list(best_aic = best_aic, best_order = best_order, best_seasonal_order = best_seasonal_order))
}

```



```{r}
best_model <- best_ARIMA(calls_ts, 2, 2, 2)

```

```{r}
best_model
```
Ya que el modelo buscado manual mente tiene un peor AIC nos quedaremos con el auto-ARIMA









